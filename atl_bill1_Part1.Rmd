---
title: "Anti-Trans Legislation Exploratory with Text Analysis (Part 1)"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
This is a workbook for the exploratory data analysis in R on the 4 anti-trans bills.

Before we did the analysis we had to do some data cleaning. Here is an example of some text
___
Be it enacted by the Legislature of the State of Arizona:

Section 1. Title 15, chapter 5, article 1, Arizona Revised Statutes, is amended by adding section 15-509, to read:

15-509. Pronouns; biological sex; parental permission; prohibition; policies

A. AN EMPLOYEE OR INDEPENDENT CONTRACTOR OF A SCHOOL DISTRICT OR CHARTER SCHOOL MAY NOT KNOWINGLY ADDRESS, IDENTIFY OR REFER TO A STUDENT WHO IS UNDER EIGHTEEN YEARS OF AGE BY EITHER OF THE FOLLOWING UNLESS THE SCHOOL DISTRICT OR CHARTER SCHOOL RECEIVES WRITTEN PERMISSION FROM THE STUDENT'S PARENT:

1. A PRONOUN THAT DIFFERS FROM THE PRONOUN THAT ALIGNS WITH THE STUDENT'S BIOLOGICAL SEX.

2. A FIRST NAME OTHER THAN THE FIRST OR MIDDLE NAME THAT IS LISTED ON THE STUDENT'S OFFICIAL SCHOOL RECORDS, EXCEPT THAT AN EMPLOYEE OR INDEPENDENT CONTRACTOR MAY ADDRESS, IDENTIFY OR REFER TO A STUDENT BY A NICKNAME THAT IS COMMONLY ASSOCIATED WITH THE STUDENT'S NAME OF RECORD.

B. A SCHOOL DISTRICT OR CHARTER SCHOOL MAY NOT REQUIRE AN EMPLOYEE OR INDEPENDENT CONTRACTOR TO ADDRESS, IDENTIFY OR REFER TO A PERSON BY A PRONOUN THAT DIFFERS FROM THE PRONOUN THAT ALIGNS WITH THE PERSON'S BIOLOGICAL SEX IF DOING SO IS CONTRARY TO THE EMPLOYEE'S OR INDEPENDENT CONTRACTOR'S RELIGIOUS OR MORAL CONVICTIONS.

C. EACH SCHOOL DISTRICT GOVERNING BOARD AND CHARTER SCHOOL GOVERNING BODY SHALL ADOPT POLICIES TO IMPLEMENT THIS SECTION.

D. THIS SECTION DOES NOT PROHIBIT ANY PERSON DESCRIBED IN SUBSECTION A OF THIS SECTION FROM DISCUSSING MATTERS OF PUBLIC CONCERN OUTSIDE THE CONTEXT OF THE PERSON'S OFFICIAL DUTIES. 
___


The initial section is metadata which describes the bill and how and where it has been amended. Keeping track of the bill revisions may be interesting, but here we are interested in the document as it stands. In addition, the addendum in this bill is a duplication of lines below.  Therefore we remove the following:
"Be it enacted by the Legislature of the State of Arizona:

Section 1. Title 15, chapter 5, article 1, Arizona Revised Statutes, is amended by adding section 15-509, to read:

15-509. Pronouns; biological sex; parental permission; prohibition; policies"

We also remove the "1. " "A. " etc before each line. We discussed how the numbering of the itemization is less important to us than the content within. Some of the documents also have bill numbers, line numbers, page numbers, or time stamps, which we remove for similar reasons.

In some legislation that reques changes to multiple sections, occassionally preamble is repeated at the start to each section. See the examples below from Florida:
___
  147         Section 5. Section 456.52, Florida Statutes, is created to
  148  read:
  149         456.52
___

___
CS/CS/HB 1421 2023
CODING: Words stricken are deletions; words underlined are additions.
hb1421-02-c2
Page 10 of 10
F L O R I D A H O U S E O F R E P R E S E N T A T I V E S
___
We pulled this in our manual cleaning of the test data sets, but may not have to be pulled.
Same with numbers, (_), and "Section 5." type headers. It may be okay to leave them in if it is a broader analysis.
"s." and "ss." could be pulled as they are short for section(s).
Sometimes line numbers have 1 space after, sometimes 2


```{r}
library(readxl)
bills <- read_excel("4-bill-test.xlsx")
View(bills)
template_leg <- read_excel("template legislation.xlsx")
View(template_leg)
probills <- read_excel("pro-LGBTQbills-test.xlsx")
View(probills)
```

## Clean data

We need some tools for text cleaning
```{r}
#install.packages("stopwords")
library(stringr)
library(stopwords)
```
Have a look at the text imported

```{r}
# we are going to do the first anti-trans bill - an Arizona bill vetoed that addresses pronoun use in schools
i = 1
ltext<-bills$text[i]
ltext
```


The syntax for removal is: 'str_replace_all(string, pattern, replacement)'. In the RStudio IDE, you can click on the function word and hit F1, and it brings up the help documentation which has some nice examples.

We will go ahead and make several substitutions and replacements. 

### Removing line breaks
```{r}
# Replace all instances of "\n" (newline) with a space - use escape characters
# You have to add a space otherwise words will run together
ltext <- str_replace_all(ltext, "\\\n", " ")
```

### Completely delete a phrase or line
``` {r}
# "\r" is carriage return
ltext <- str_replace_all(ltext, "\\\r", " ")

# We are going to remove "." and "," next. There are a few reasons for this. I see U.S. will be US and there are some places where the end "." is interfering with removing/matching some words for replacement and removal.

# If we were looking at word/sentence relationships, we may have wanted to keep periods and question marks first to define sentences before breaking up into words. 
ltext <- str_replace_all(ltext, "\\.", "")
ltext <- str_replace_all(ltext, ",", " ")
ltext <- str_replace_all(ltext, "'", "")
ltext <- str_replace_all(ltext, "’", "")
ltext <- str_replace_all(ltext, "‘", "")
ltext <- str_replace_all(ltext, "“", "")
ltext <- str_replace_all(ltext, "”", "")
ltext <- str_replace_all(ltext, "-", "")
ltext <- str_replace_all(ltext, ":", " ")
ltext <- str_replace_all(ltext, "/", "")
ltext <- str_replace_all(ltext, "\\\\", "") #remove \
ltext <- str_replace_all(ltext, ";", " ")
#ltext <- str_replace_all(ltext, "\\?", "")

# We also have () and [] to be removed
ltext <- str_replace_all(ltext, "\\(|\\)|\\[|\\]", "")

#lets check progress
ltext

```

### Delete certain phrases

``` {r}
# This text tends to have a 1. and a. and (a) and (b). We already eliminated parentheses and periods, so now we are going to eliminate all single letter words and numbers.  We are intentionally not removing all numbers. There are several references to k12 or under 18 so we want to maintain these.
ltext <- str_replace_all(ltext, " [a-zA-Z0-9] ", " ")

# We now want to make sure that our words will be recognized as the same when we construct relationships, so we have to converting everything to lowercase.
ltext <- str_to_lower(ltext)
ltext
```

Finally, we clean up redundant spaces
``` {r}
# Replace multiple spaces with one space
# s+ means 1 or more spaces.  \\ are escape characters
ltext <- str_replace_all(ltext, "\\s+", " ")
```

Check to make sure there isn't anything else that needs removing, such as numbers.

``` {r}
# Delete spaces at the start and end of our text
ltext<-trimws(ltext, "both")
```


### Cleaning for an effective text analysis

Are there any words that make sense to eliminate in our analysis?

``` {r}
# Identify stop words
# stopwords gives us a list of such words
# otherwise we could manually define these, or even add to this list
stopwords_regex = paste(stopwords('en'), collapse = '\\b|\\b')
stopwords_regex = paste0('\\b', stopwords_regex, '\\b')
ltext <- str_replace_all(ltext, stopwords_regex, '')
```


### Get a vector of words
We now have one list of words in a 1x1 matrix. We need to convert that to a vector with one word in each slot.

``` {r}
# Remember that strsplit returns a list of lists
ltext_ls<- str_split(ltext, " ")
```

I recommend viewing 'ltext_ls' to get a sense of how the list looks.  

I am saving this as a vector and exporting it to csv for later independent use. You can also structure your word vector data so that each row in "bills" is duplicated and then a word vector row. So if my bill had 4 words, I can have 4 rows for bill1 that have the same descriptor data (e.g. Healthcare) and but under the "words" column, rown 1 has the first word, row 2 has the second word, etc. That is probably the best way to structure the data, but it makes it harder to visualize the data when you have over 400 words like bill 1 actually has.

``` {r}
# Grab just the vector
ltext_vec<- ltext_ls[[1]]

# convert to data frame
ltext_vec<-as.data.frame(ltext_vec)
colnames(ltext_vec) <- c("words")

#write a csv of the cleaned words.  That way you can just do the next section without running the cleaning parts.
billname = paste0("bill_",i)
write.csv(ltext_vec, file = billname, row.names = FALSE)
```
