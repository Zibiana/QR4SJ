	<section xml:id="sec-leg-textualize">
		<title>Textualizing the Data</title>
	<introduction>
		<title>Motivating Ideas</title>
			<p> In this section, I will... </p>
				<ul>
					<li> Understand the definition and process of text analysis. </li>
					<li> Know how to clean data for text analysis. </li>
					<li> Know how to create qualitative visualizations. </li>
					<li> Understand how to use text analysis to interpret legislation. </li>
				</ul>	
		
	</introduction>

		<subsection xml:id="cleaning-for-text-analysis">

			<title>Cleaning for Text Analysis</title>
			<p>
				Text analysis is the process of using computer systems to understand human-written text for analysis purposes including analyzing legislation. Text can be analyzed from unstructured data sources such as emails, surveys, documents, and other online material to extract insights. The main feature of text analysis is training computer software to associate words with meanings, similar to how humans learn a new language through objects, actions, and emotions. Deep learning and natural language processing (NLP) are the principles of text analysis. <url href = "https://aws.amazon.com/what-is/text-analysis/">(Source).</url>
			</p>
			<p>
			The goal of this section is to give foundational steps to clean a txt document in R studio and then use R studio to analyze the text using frequency analysis, bigrams, and optionally networks. 		
			</p>	
			<p>
				In this chapter, you will explore anti-trans legislation through text analysis. Note, this approach requires additional cleaning. This cleaning process depends on the specific bill, its formatting, and your group’s preferences. Decisions must be made about how much you want to clean the data for your specific project. 
			</p>

			<p>
				Note: whenever you download a file to open in R or R Studio, make sure to set your working directory to wherever that file is located. For example, if you have the file just on your desktop (not in any folder), entering <em> “setwd("~/Desktop")” </em> in the console window will set the working directory to your desktop.
			</p>
			
			<activity>
				<p> Before we do any text analysis, we have to do some data cleaning. We will use an Arizona bill regarding trans legislation as an example, which can be viewed <url href = "https://github.com/DAAAAMNSocialJustice/anti-trans-legislation/blob/3f450de86643b58c20df51e910cf7ebd8c4a266e/4-bill-test.xlsx"> here </url>. </p>

				<p> After downloading the "4-bill-test" excel file, we can enter the following code in R: </p>
				<p> <image source="Textualizing the Data Images/Text Analysis Image 1.png"/> </p>
				<p> This will install some necessary packages for cleaning and read the excel file into R. We want to look at first anti-trans bill in the excel file- an Arizona bill vetoed that addresses pronoun use in schools. Add the following code below what you already have: </p>
				<p> <image source="Textualizing the Data Images/Text Analysis Image 2.png"/> </p>
				<p> This code will output the first row of text of the bills file. We will now clean this section with the following code. Run each block one at a time along with the code from above. You can enter "ltext" at any point to check your progress. </p>
				<ol> 
					<li> 
						<p> Removing line breaks. </p> 
						<p> <image source="Textualizing the Data Images/Text Analysis Image 3.png"/> </p>
					</li>
					<li>  
						<p> Deleting punctuation. </p> 
						<p> <image source="Textualizing the Data Images/Text Analysis Image 4.png"/> </p>
					</li>
					<li>  
						<p> Deleting a phrase or line. </p> <p> This text tends to have a 1. and a. and (a) and (b). We already eliminated parentheses and periods, so now we are going to eliminate all single letter words and numbers.  We are intentionally not removing all numbers. There are several references to K12 or under 18 so we want to maintain these. We also want to make sure that our words will be recognized as the same when we construct relationships, so we have to convert everything to lowercase. </p>
						<p> <image source="Textualizing the Data Images/Text Analysis Image 5.png"/> </p>
					</li>
					<li>  
						<p> Removing redundant spaces. </p> 
						<p> <image source="Textualizing the Data Images/Text Analysis Image 6.png"/> </p>
					</li>
					<li>  
						<p> Identifying and eliminating stop words. </p> <p> Stop words are common words that carry little textual meaning, so we do not need to include them in our analysis. For example, "the", "are", "is", etc... </p>
						<p> <image source="Textualizing the Data Images/Text Analysis Image 7.png"/> </p>
					</li>
				</ol>
				<p> After cleaning the data, a block of text remains. </p>
				<p> <image source="Textualizing the Data Images/Text Analysis Image 8.png"/> </p>
				<p> In order to analyze the block of text, we need to get these words into what is called a word vector. For those unfamiliar with the idea of vectors, word vectors are a list of words, with one word on each line. If you are familiar with vectors from other math courses, the idea of a word vector is similar: it is a list of words in an array format. We can create a word vector and save it as a new csv file with the following code: </p>
				<p> <image source="Textualizing the Data Images/Text Analysis Image 9.png"/> </p>
				<p> You can enter "ltext_vec" to view our word vector. Play with the following code to analyze your text.</p>
				<p> <image source="Textualizing the Data Images/Text Analysis Image 10.png"/> </p>
				<p> We can note that the relative frequency (rflel) is the number of times a particular value for a variable has been observed in relation to the total number of values for that variable. We can also see from our top 20 list that "school" and "pronoun" were of the most common words used in the text. This makes sense given the context of this bill. </p>
				<p> <image source="Textualizing the Data Images/Text Analysis Image 11.png"/> </p>
			</activity>
		</subsection>

		<subsection xml:id="visualizing-text-analysis-data">
			<title>Visualizing Text Analysis Data</title>
			<p> We can continue our investigation of the bill by creating and analyzing visualizations. </p>

			<activity>
				<ol>
					<li> Download the <url href = "https://github.com/DAAAAMNSocialJustice/anti-trans-legislation/blob/3f450de86643b58c20df51e910cf7ebd8c4a266e/atl_heritage.Rmd">atl_heritage.Rmd</url>, <url href = "https://github.com/DAAAAMNSocialJustice/anti-trans-legislation/blob/3f450de86643b58c20df51e910cf7ebd8c4a266e/4-bill-test.xlsx">4-bill-test.xlsx</url>, <url href="https://github.com/DAAAAMNSocialJustice/anti-trans-legislation/blob/3f450de86643b58c20df51e910cf7ebd8c4a266e/template%20legislation.xlsx">template legislation.xlsx</url>, and <url href = "https://github.com/DAAAAMNSocialJustice/anti-trans-legislation/blob/3f450de86643b58c20df51e910cf7ebd8c4a266e/Pro-LGBTQ-Bills.csv">Pro-LGBTQ-Bills.csv</url> files from <url href = "https://github.com/DAAAAMNSocialJustice/anti-trans-legislation">GitHub</url>. </li>
					<li> Open atl_heritage.Rmd in R Studio and run the code by selecting Run→Run All. A small yellow banner may pop up at the top of your screen that you do not have a library installed. Press “Install,” and run the code again. </li>
					<li> Tabs named “bills,” “template_leg,” “probills,” “ltext_cuonts,” and “counts_ordered” appear in the bar next to the original .Rmd file. What information do each of these tabs contain? </li>
					<li> After running the code, some tables and graphs will appear directly in the code. Return to the .Rmd tab and scroll through the code until you find the following table. How many times does the word “employee” appear in the bill? Hint: look at the “n” column. What is the relative frequency of the word “education”? Hint: look at the “relf” column. </li>
					<p> <image source="5.3 - 5.5 Images/5.4 Activity 3 Q4.png"/> </p>
					<li> Continue to scroll through the graphs. Talk with a partner about what looks nice in each graph, and what you would want to change. Which graph is your favorite? Why? </li>
				</ol>
			</activity>
		</subsection>
		
		<subsection xml:id="subsec-leg-textual-exercise">
			<title>Exercises</title>
			<p> Now, it&apos;s your turn to try! </p>
			<exercise> 
				<p> Using the following graph, answer the questions 1-6. </p>
				<p> <image source="5.3 - 5.5 Images/5.4 Exercise Q1.png"/> </p>
				<ol>
					<li> What does the label “n” on the y-axis mean? </li>
					<li> What title would you give to the graph? </li>
					<li> How many words appear exactly 5 times in the bill? </li>
					<li> How many words appear at least 7 times in the bill? </li>
					<li> What word appears the most? </li>
					<li> What might this information tell us about the bill? </li>
				</ol>
			</exercise>

			<exercise>
				<p> List 3 things you can do to clean data learned in Section 5.4 and 3 things you can do to clean data for text analysis (discussed in this section). What are some similarities and differences between the methods you came up with?</p>
			</exercise>

			<exercise>
				<p> What do you think would happen if you didn&apos;t clean the data before making a word vector? How might the graph look different? </p>
			</exercise>

			<exercise>
				<p> Which cleaning method for text analysis do you think would be most useful to learn? Why? This question is asking for an opinion, there is no right answer. </p>
			</exercise>
		</subsection>
	</section>

